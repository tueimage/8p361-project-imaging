{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Neural networks for classification\n",
    "\n",
    "The goal of this assignment is to get familiar with the Keras neural networks API. You will implement a neural network for (non-medical) image classification example — classification of images of handwritten digits, and perform some basic experiments and analysis. \n",
    "\n",
    "In this assignment, you will run trough Python code that demonstrates how to train a neural network for handwritten digit recognition. For this purpose, we are going to use the well-known [MNIST dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "The neural network is implemented in the Keras neural networks API. An overview of the Keras API was given during the introductory lectures. More details can be found in the [Keras API documentation](https://keras.io/).\n",
    "\n",
    "### Preliminaries\n",
    "\n",
    "The first step in the implementation is to import all the Python modules that will be used throughout the code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a brief description of the modules and functions that are imported:\n",
    "- NumPy is a Python library for scientific computing. You can think of it as a libarary that implements MATLAB-like functionality in Python, although note that NumPy is not a Matlab clone. This is a NumPy cheatsheat for MATLAB users that you might find useful: https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html\n",
    "\n",
    "- matplotlib.pyplot is a module that provides MATLAB-style plotting in Python. The pyplot documentation can be found here: https://matplotlib.org/api/pyplot_api.html#module-matplotlib.pyplot\n",
    "\n",
    "- scikit-learn is a machine learning library for Python. From this library we are going to use the `train_test_split` function that is documented here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "- Finally, we import a number of modules from the Keras API.\n",
    "\n",
    "### Loading the MNIST dataset\n",
    "\n",
    "The following lines of code use the builtin Keras method to load the MNIST dataset that is already split into training and test sets and then visualizes some example images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset using the builtin Keras method\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('Dimensionality of the training image dataset and labels:')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Dimensionality of the test image dataset and labels:')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# show the first image in the dataset\n",
    "plt.figure()\n",
    "plt.imshow(X_train[0], cmap='gray_r', vmin=0, vmax=255)\n",
    "plt.title('First image in the dataset')\n",
    "\n",
    "# show the first 16 images in the dataset in a 4x4 gird\n",
    "fig = plt.figure()\n",
    "for n in range(16):\n",
    "    ax = fig.add_subplot(4, 4, n + 1)\n",
    "    plt.imshow(X_train[n], cmap='gray_r', vmin=0, vmax=255)   \n",
    "    plt.axis('off')\n",
    "fig.suptitle('First 100 images in the dataset')\n",
    "plt.show()\n",
    "\n",
    "# print the labels of the first 16 images in the dataset\n",
    "print('Labels of the first 16 images in the dataset:')\n",
    "print(y_train[:16])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "The next step is to preprocess the data, i.e. prepare it in a format that will make it easy to train and evaluate machine learning models such as neural networks. The MNIST dataset already is split into a training and validation sets, however, we will also require a validation set to monitor for overfitting (and perform model selection). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive a validation set from the training set\n",
    "# the original training set is split into \n",
    "# new training set (90%) and a validation set (10%)\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.10, random_state=101)\n",
    "y_train, y_val = train_test_split(y_train, test_size=0.10, random_state=101)\n",
    "\n",
    "\n",
    "print('Dimensionality of the new training image dataset and labels:')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "print('Dimensionality of the validation image dataset and labels:')\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the distribution of the class labels in the new training and validation sets and make sure they are similarly distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_classes(y, num_class=10):\n",
    "    plt.figure()\n",
    "    plt.hist(y, bins=range(0,num_class+1), align='left', rwidth=0.9)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Class count')\n",
    "    plt.xticks(range(0,num_class))\n",
    "    plt.title('Class distribution')\n",
    "\n",
    "    \n",
    "# show the class label distribution in the training dataset\n",
    "plt_classes(y_train)\n",
    "\n",
    "# show the class label distribution in the validation dataset\n",
    "plt_classes(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code reshape the MNIST dataset to the appropriate format, convert the dataset to float32 data type (from uint8) and finally normalize to the intensity values to the [0, 1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of the data matrix is NxHxW, where\n",
    "# N is the number of images,\n",
    "# H and W are the height and width of the images\n",
    "# keras expect the data to have shape NxHxWxC, where\n",
    "# C is the channel dimension\n",
    "X_train = np.reshape(X_train, (-1,28,28,1)) \n",
    "X_val = np.reshape(X_val, (-1,28,28,1))\n",
    "X_test = np.reshape(X_test, (-1,28,28,1))\n",
    "\n",
    "\n",
    "# convert the datatype to float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "\n",
    "# normalize our data values to the range [0,1]\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST classification problem has 10 classes, one for each digit. Thus, the output neural network should have 10 output neurons, each one corresponding to one of the classes. This means that the targets that will be used to train the network must be 10-dimensional vectors so they are directly comparable to the output neurons. This can be achieved by one-hot encoding of the class labels, which is performed in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class label preprocessing for keras\n",
    "\n",
    "# we see that we have a 1D-array with length 54000\n",
    "print(y_train.shape) \n",
    "\n",
    "\n",
    "# since we have 10 different classes, what does this array look like?\n",
    "# let's look at the first 20 labels\n",
    "print(y_train[:20]) \n",
    "\n",
    "\n",
    "# convert 1D class arrays to 10D class matrices\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_val = to_categorical(y_val, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "# check the output\n",
    "print(y_train.shape)\n",
    "# this is now a one-hot encoded matrix\n",
    "print(y_train[:20]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a neural network classification model\n",
    "\n",
    "Now that the input (images) and output (targets) data is prepared, we can proceed to defining the neural network model that will later be trained with the data. Note that we use a sequential Keras model and the first layer of the model flattens the input images (converts them to 1D arrays). \n",
    "\n",
    "The neural network consists of one input layer, one hidden layer of 64 neurons activated with a ReLU nonlinearity, and one output layer activated with a softmax nonlinearity. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# flatten the 28x28x1 pixel input images to a row of pixels (a 1D-array)\n",
    "model.add(Flatten(input_shape=(28,28,1))) \n",
    "# fully connected layer with 64 neurons and ReLU nonlinearity\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# output layer with 10 nodes (one for each class) and softmax nonlinearity\n",
    "model.add(Dense(10, activation='softmax')) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Finally, the model can be trained trained with stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# use this variable to name your model\n",
    "model_name=\"my_first_model\"\n",
    "\n",
    "# create a way to monitor our model in Tensorboard\n",
    "tensorboard = TensorBoard(\"logs/{}\".format(model_name))\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_val, y_val), callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation loss curves in TensorBoard\n",
    "\n",
    "In the call to the `model.fit()` method, we provided a TensorBoard callback function as a parameter. This function logs the training process. The generated logs can be used to plot the training and validation loss and accuracy curves. \n",
    "\n",
    "You can start TensorBoard by calling the following commands from the Anaconda Prompt command line:\n",
    "\n",
    "````bash\n",
    "activate 8p361\n",
    "cd 'path/where/logs/are'\n",
    "tensorboard --logdir logs\n",
    "````\n",
    "\n",
    "This will start TensorBoard. While TensorBoard is running, you can navigate your browser to http://localhost:6006/ to visualize the training and validation loss curves.\n",
    "\n",
    "If you use different names for your trained models, you can easily compare their loss and accuracy curves in TensorBoard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the performance of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "\n",
    "print(\"Loss: \",score[0])\n",
    "print(\"Accuracy: \",score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you start with the exercises...\n",
    "\n",
    "While this Python notebook such as this one can be very useful tools for presenting code in an instructive way, they can be a bit inconvenient for performing and keeping track of large number of experiments (such as experiments with different neural network architecture). The Python file `mlp.py` contains all the code from this notebook minus the analysis and visualization experiments. You can use this code as the basis of the experiments you need to perform in the exercises.\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "The example neural network classification model in this assignment is relatively simple — it contains a single hidden layer of 64 neurons. \n",
    "\n",
    "Perform a set of experiments with more complex models, e.g. with more layers (deeper models), more neurons per layer or a combination. \n",
    "\n",
    "Describe the set of experiments that you have performed. What is the accuracy of the best model? How did you determine which model is the best?\n",
    "\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "Compare the performance of the following three models:\n",
    "1. Neural netowrk without any hidden layers (the input layer connects directly to the output layer).\n",
    "2. Neural network with 3 hidden layers with ReLU activations.\n",
    "3. Neural network with 3 hidden layers with linear activations (i.e. without nonlinearities between the layers). \n",
    "\n",
    "Analyze the performance of the three models. What is the reason behind the difference in performance between the second and third models?\n",
    "\n",
    "## Exercise 3\n",
    "\n",
    "Train a neural network model (the specific architecture is up to you) for a four class classification problem derived from MNIST in the following way:\n",
    "\n",
    "- \"vertical digits\": 1, 7\n",
    "- \"loopy digits\": 0, 6, 8, 9\n",
    "- \"curly digits\": 2, 5\n",
    "- \"other\": 3, 4\n",
    "\n",
    "## Submission checklist\n",
    "\n",
    "- Exercise 1: Answers to the questions and code\n",
    "- Exercise 2: Answers to the questions and code\n",
    "- Exercise 3: Code\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
